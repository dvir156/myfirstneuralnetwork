{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "                               rotation_range=30,\n",
    "                               width_shift_range=0.1,\n",
    "                               height_shift_range=0.1,\n",
    "                               shear_range=0.01,\n",
    "                               zoom_range=[0.8, 1.25],\n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=False,\n",
    "                               fill_mode='reflect',\n",
    "                               data_format='channels_last',\n",
    "                               brightness_range=[0.5, 1.5]) #included in our dependencies\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "                               rotation_range=30,\n",
    "                               width_shift_range=0.1,\n",
    "                               height_shift_range=0.1,\n",
    "                               shear_range=0.01,\n",
    "                               zoom_range=[0.8, 1.25],\n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=False,\n",
    "                               fill_mode='reflect',\n",
    "                               data_format='channels_last',\n",
    "                               brightness_range=[0.5, 1.5]) #included in our dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7040 images belonging to 100 classes.\n",
      "Found 1988 images belonging to 100 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = (224,224)\n",
    "batch_size = 10\n",
    "\n",
    "training_data_dir = r'C:\\Users\\dvir1\\Study\\deep learning\\project\\train'\n",
    "validation_data_dir = r'C:\\Users\\dvir1\\Study\\deep learning\\project\\validation'\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(training_data_dir,\n",
    "                                                 target_size=image_size,\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "                                        validation_data_dir,\n",
    "                                         target_size=image_size,\n",
    "                                         color_mode='rgb',\n",
    "                                        class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(train_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.add(Conv2D(128, (3,3), input_shape = (image_size[0], image_size[1], 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.add(Conv2D(128, (3,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b274e4c017f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "base_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "base_model.add(Conv2D(256, (3,3)))\n",
    "base_model.add(Conv2D(256, (3,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "base_model.add(Conv2D(256, (3,3)))\n",
    "base_model.add(Conv2D(256, (3,3)))\n",
    "base_model.add(MaxPooling2D(pool_size=(2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classCount = 100\n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(classCount,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "model_final=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_input (InputLayer)    (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 222, 222, 128)     3584      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 220, 220, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 108, 108, 256)     295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 106, 106, 256)     590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 53, 53, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 51, 51, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 49, 49, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               51300     \n",
      "=================================================================\n",
      "Total params: 4,105,444\n",
      "Trainable params: 4,105,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_final.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704\n"
     ]
    }
   ],
   "source": [
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "print(step_size_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossAccHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.accuracy = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.accuracy.append(logs.get('acc'))\n",
    "        \n",
    "history = LossAccHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "704/704 [==============================] - 229s 325ms/step - loss: 5.0012 - acc: 0.0278 - val_loss: 4.5508 - val_acc: 0.0332\n",
      "Epoch 2/10\n",
      "704/704 [==============================] - 223s 317ms/step - loss: 4.4415 - acc: 0.0456 - val_loss: 4.3594 - val_acc: 0.0458\n",
      "Epoch 3/10\n",
      "704/704 [==============================] - 223s 317ms/step - loss: 4.3573 - acc: 0.0516 - val_loss: 4.2421 - val_acc: 0.0563\n",
      "Epoch 4/10\n",
      "704/704 [==============================] - 221s 314ms/step - loss: 4.2564 - acc: 0.0584 - val_loss: 4.2273 - val_acc: 0.0634\n",
      "Epoch 5/10\n",
      "704/704 [==============================] - 221s 314ms/step - loss: 4.2051 - acc: 0.0662 - val_loss: 4.2669 - val_acc: 0.0578\n",
      "Epoch 6/10\n",
      "704/704 [==============================] - 222s 315ms/step - loss: 4.1658 - acc: 0.0685 - val_loss: 4.2853 - val_acc: 0.0523\n",
      "Epoch 7/10\n",
      "704/704 [==============================] - 222s 315ms/step - loss: 4.1354 - acc: 0.0761 - val_loss: 4.0641 - val_acc: 0.0780\n",
      "Epoch 8/10\n",
      "704/704 [==============================] - 222s 316ms/step - loss: 4.0936 - acc: 0.0776 - val_loss: 4.0860 - val_acc: 0.0739\n",
      "Epoch 9/10\n",
      "704/704 [==============================] - 222s 316ms/step - loss: 4.0373 - acc: 0.0834 - val_loss: 4.0927 - val_acc: 0.0795\n",
      "Epoch 10/10\n",
      "704/704 [==============================] - 225s 320ms/step - loss: 4.0016 - acc: 0.0864 - val_loss: 4.0253 - val_acc: 0.0820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21cf1aa9a58>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final.fit_generator(generator=train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   validation_data = validation_generator,\n",
    "                   epochs=10\n",
    "                   ,callbacks = [history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=2, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "networkfileName = \"vgg16_{}.h5\".format(int(time.time()))\n",
    "checkpoint = ModelCheckpoint(networkfileName, monitor='val_acc', verbose=1,\n",
    "                             save_best_only=True, save_weights_only=False, mode='auto', period=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "704/704 [==============================] - 223s 316ms/step - loss: 3.9682 - acc: 0.0942 - val_loss: 4.0684 - val_acc: 0.0795\n",
      "Epoch 2/25\n",
      "704/704 [==============================] - 222s 315ms/step - loss: 3.9101 - acc: 0.1001 - val_loss: 3.9686 - val_acc: 0.0971\n",
      "Epoch 3/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 3.8689 - acc: 0.1063\n",
      "Epoch 00003: val_acc improved from -inf to 0.11167, saving model to vgg16_1549893243.h5\n",
      "704/704 [==============================] - 223s 317ms/step - loss: 3.8684 - acc: 0.1061 - val_loss: 3.8757 - val_acc: 0.1117\n",
      "Epoch 4/25\n",
      "704/704 [==============================] - 223s 317ms/step - loss: 3.8231 - acc: 0.1178 - val_loss: 3.8392 - val_acc: 0.1172\n",
      "Epoch 5/25\n",
      "704/704 [==============================] - 223s 316ms/step - loss: 3.7808 - acc: 0.1203 - val_loss: 3.8552 - val_acc: 0.1112\n",
      "Epoch 6/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 3.7378 - acc: 0.1310\n",
      "Epoch 00006: val_acc improved from 0.11167 to 0.11922, saving model to vgg16_1549893243.h5\n",
      "704/704 [==============================] - 222s 315ms/step - loss: 3.7372 - acc: 0.1313 - val_loss: 3.7641 - val_acc: 0.1192\n",
      "Epoch 7/25\n",
      "704/704 [==============================] - 222s 315ms/step - loss: 3.6750 - acc: 0.1311 - val_loss: 3.7186 - val_acc: 0.1368\n",
      "Epoch 8/25\n",
      "704/704 [==============================] - 221s 314ms/step - loss: 3.6184 - acc: 0.1500 - val_loss: 3.8597 - val_acc: 0.1333\n",
      "Epoch 9/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 3.5948 - acc: 0.1512\n",
      "Epoch 00009: val_acc improved from 0.11922 to 0.14135, saving model to vgg16_1549893243.h5\n",
      "704/704 [==============================] - 224s 318ms/step - loss: 3.5946 - acc: 0.1511 - val_loss: 3.7474 - val_acc: 0.1413\n",
      "Epoch 10/25\n",
      "704/704 [==============================] - 222s 315ms/step - loss: 3.5432 - acc: 0.1646 - val_loss: 3.5992 - val_acc: 0.1630\n",
      "Epoch 11/25\n",
      "704/704 [==============================] - 221s 314ms/step - loss: 3.4882 - acc: 0.1710 - val_loss: 3.5689 - val_acc: 0.1590\n",
      "Epoch 12/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 3.4582 - acc: 0.1754\n",
      "Epoch 00012: val_acc improved from 0.14135 to 0.16901, saving model to vgg16_1549893243.h5\n",
      "704/704 [==============================] - 222s 315ms/step - loss: 3.4580 - acc: 0.1753 - val_loss: 3.5675 - val_acc: 0.1690\n",
      "Epoch 13/25\n",
      "704/704 [==============================] - 222s 316ms/step - loss: 3.4073 - acc: 0.1922 - val_loss: 3.5243 - val_acc: 0.1670\n",
      "Epoch 14/25\n",
      "704/704 [==============================] - 221s 314ms/step - loss: 3.3586 - acc: 0.1915 - val_loss: 3.3938 - val_acc: 0.2047\n",
      "Epoch 15/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 3.3186 - acc: 0.1932\n",
      "Epoch 00015: val_acc improved from 0.16901 to 0.20875, saving model to vgg16_1549893243.h5\n",
      "704/704 [==============================] - 223s 316ms/step - loss: 3.3175 - acc: 0.1935 - val_loss: 3.3537 - val_acc: 0.2088\n",
      "Epoch 16/25\n",
      "704/704 [==============================] - 223s 317ms/step - loss: 3.2655 - acc: 0.2071 - val_loss: 3.2998 - val_acc: 0.2188\n",
      "Epoch 17/25\n",
      "704/704 [==============================] - 224s 319ms/step - loss: 3.2045 - acc: 0.2188 - val_loss: 3.3455 - val_acc: 0.2138\n",
      "Epoch 18/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 3.1420 - acc: 0.2300\n",
      "Epoch 00018: val_acc did not improve from 0.20875\n",
      "704/704 [==============================] - 224s 318ms/step - loss: 3.1418 - acc: 0.2300 - val_loss: 3.4044 - val_acc: 0.1972\n",
      "Epoch 00018: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21cf1d95b00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = LossAccHistory()\n",
    "model_final.fit_generator(generator=train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   validation_data = validation_generator,\n",
    "                   epochs=25\n",
    "                   ,callbacks = [history, checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "networkfileName = \"Gabis_{}.h5\".format(int(time.time()))\n",
    "checkpoint = ModelCheckpoint(networkfileName, monitor='val_acc', verbose=1,\n",
    "                             save_best_only=True, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 3.1013 - acc: 0.2432\n",
      "Epoch 00001: val_acc improved from -inf to 0.23994, saving model to Gabis_1549897763.h5\n",
      "704/704 [==============================] - 222s 316ms/step - loss: 3.1012 - acc: 0.2433 - val_loss: 3.2554 - val_acc: 0.2399\n",
      "Epoch 2/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 3.0387 - acc: 0.2555\n",
      "Epoch 00002: val_acc did not improve from 0.23994\n",
      "704/704 [==============================] - 222s 315ms/step - loss: 3.0395 - acc: 0.2553 - val_loss: 3.3059 - val_acc: 0.2238\n",
      "Epoch 3/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 3.0157 - acc: 0.2688\n",
      "Epoch 00003: val_acc improved from 0.23994 to 0.26308, saving model to Gabis_1549897763.h5\n",
      "704/704 [==============================] - 223s 317ms/step - loss: 3.0146 - acc: 0.2690 - val_loss: 3.1733 - val_acc: 0.2631\n",
      "Epoch 4/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.9689 - acc: 0.2745\n",
      "Epoch 00004: val_acc did not improve from 0.26308\n",
      "704/704 [==============================] - 221s 313ms/step - loss: 2.9690 - acc: 0.2744 - val_loss: 3.3119 - val_acc: 0.2118\n",
      "Epoch 5/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.9147 - acc: 0.2835\n",
      "Epoch 00005: val_acc did not improve from 0.26308\n",
      "704/704 [==============================] - 222s 315ms/step - loss: 2.9135 - acc: 0.2838 - val_loss: 3.1350 - val_acc: 0.2394\n",
      "Epoch 6/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.8357 - acc: 0.2969\n",
      "Epoch 00006: val_acc improved from 0.26308 to 0.26610, saving model to Gabis_1549897763.h5\n",
      "704/704 [==============================] - 224s 318ms/step - loss: 2.8375 - acc: 0.2967 - val_loss: 3.0943 - val_acc: 0.2661\n",
      "Epoch 7/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.8203 - acc: 0.3121\n",
      "Epoch 00007: val_acc improved from 0.26610 to 0.28722, saving model to Gabis_1549897763.h5\n",
      "704/704 [==============================] - 222s 315ms/step - loss: 2.8197 - acc: 0.3122 - val_loss: 2.9517 - val_acc: 0.2872\n",
      "Epoch 8/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.7552 - acc: 0.3183\n",
      "Epoch 00008: val_acc improved from 0.28722 to 0.30584, saving model to Gabis_1549897763.h5\n",
      "704/704 [==============================] - 221s 314ms/step - loss: 2.7546 - acc: 0.3183 - val_loss: 2.9339 - val_acc: 0.3058\n",
      "Epoch 9/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.7218 - acc: 0.3213\n",
      "Epoch 00009: val_acc improved from 0.30584 to 0.33350, saving model to Gabis_1549897763.h5\n",
      "704/704 [==============================] - 222s 315ms/step - loss: 2.7203 - acc: 0.3214 - val_loss: 2.8116 - val_acc: 0.3335\n",
      "Epoch 10/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.6651 - acc: 0.3385\n",
      "Epoch 00010: val_acc did not improve from 0.33350\n",
      "704/704 [==============================] - 223s 317ms/step - loss: 2.6650 - acc: 0.3386 - val_loss: 2.7981 - val_acc: 0.3310\n",
      "Epoch 11/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.5944 - acc: 0.3552\n",
      "Epoch 00011: val_acc did not improve from 0.33350\n",
      "704/704 [==============================] - 226s 321ms/step - loss: 2.5956 - acc: 0.3547 - val_loss: 2.8186 - val_acc: 0.3285\n",
      "Epoch 12/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.5617 - acc: 0.3647\n",
      "Epoch 00012: val_acc improved from 0.33350 to 0.33451, saving model to Gabis_1549897763.h5\n",
      "704/704 [==============================] - 221s 314ms/step - loss: 2.5622 - acc: 0.3645 - val_loss: 2.7524 - val_acc: 0.3345\n",
      "Epoch 13/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.4983 - acc: 0.3797\n",
      "Epoch 00013: val_acc did not improve from 0.33451\n",
      "704/704 [==============================] - 222s 315ms/step - loss: 2.4976 - acc: 0.3800 - val_loss: 2.8211 - val_acc: 0.3345\n",
      "Epoch 14/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.4274 - acc: 0.3962\n",
      "Epoch 00014: val_acc improved from 0.33451 to 0.34356, saving model to Gabis_1549897763.h5\n",
      "704/704 [==============================] - 222s 316ms/step - loss: 2.4268 - acc: 0.3963 - val_loss: 2.7382 - val_acc: 0.3436\n",
      "Epoch 15/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.4432 - acc: 0.3913\n",
      "Epoch 00015: val_acc improved from 0.34356 to 0.35010, saving model to Gabis_1549897763.h5\n",
      "704/704 [==============================] - 222s 315ms/step - loss: 2.4425 - acc: 0.3915 - val_loss: 2.7556 - val_acc: 0.3501\n",
      "Epoch 16/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.3719 - acc: 0.4129\n",
      "Epoch 00016: val_acc did not improve from 0.35010\n",
      "704/704 [==============================] - 221s 314ms/step - loss: 2.3724 - acc: 0.4129 - val_loss: 2.7372 - val_acc: 0.3466\n",
      "Epoch 17/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.3019 - acc: 0.4128\n",
      "Epoch 00017: val_acc improved from 0.35010 to 0.35312, saving model to Gabis_1549897763.h5\n",
      "704/704 [==============================] - 222s 316ms/step - loss: 2.3019 - acc: 0.4129 - val_loss: 2.7763 - val_acc: 0.3531\n",
      "Epoch 18/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.2765 - acc: 0.4287\n",
      "Epoch 00018: val_acc improved from 0.35312 to 0.37223, saving model to Gabis_1549897763.h5\n",
      "704/704 [==============================] - 222s 316ms/step - loss: 2.2772 - acc: 0.4288 - val_loss: 2.7300 - val_acc: 0.3722\n",
      "Epoch 19/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.2206 - acc: 0.4451\n",
      "Epoch 00019: val_acc improved from 0.37223 to 0.38934, saving model to Gabis_1549897763.h5\n",
      "704/704 [==============================] - 221s 314ms/step - loss: 2.2214 - acc: 0.4447 - val_loss: 2.6564 - val_acc: 0.3893\n",
      "Epoch 20/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.1695 - acc: 0.4495\n",
      "Epoch 00020: val_acc improved from 0.38934 to 0.40644, saving model to Gabis_1549897763.h5\n",
      "704/704 [==============================] - 226s 321ms/step - loss: 2.1700 - acc: 0.4493 - val_loss: 2.5811 - val_acc: 0.4064\n",
      "Epoch 21/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.1437 - acc: 0.4603\n",
      "Epoch 00021: val_acc improved from 0.40644 to 0.42254, saving model to Gabis_1549897763.h5\n",
      "704/704 [==============================] - 224s 318ms/step - loss: 2.1446 - acc: 0.4599 - val_loss: 2.4875 - val_acc: 0.4225\n",
      "Epoch 22/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.1148 - acc: 0.4627\n",
      "Epoch 00022: val_acc did not improve from 0.42254\n",
      "704/704 [==============================] - 233s 332ms/step - loss: 2.1152 - acc: 0.4626 - val_loss: 2.8003 - val_acc: 0.3581\n",
      "Epoch 23/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.0668 - acc: 0.4735\n",
      "Epoch 00023: val_acc did not improve from 0.42254\n",
      "704/704 [==============================] - 227s 322ms/step - loss: 2.0664 - acc: 0.4734 - val_loss: 2.4167 - val_acc: 0.4145\n",
      "Epoch 24/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 2.0067 - acc: 0.4905\n",
      "Epoch 00024: val_acc improved from 0.42254 to 0.42907, saving model to Gabis_1549897763.h5\n",
      "704/704 [==============================] - 227s 322ms/step - loss: 2.0063 - acc: 0.4905 - val_loss: 2.4224 - val_acc: 0.4291\n",
      "Epoch 25/25\n",
      "703/704 [============================>.] - ETA: 0s - loss: 1.9819 - acc: 0.4966\n",
      "Epoch 00025: val_acc improved from 0.42907 to 0.44014, saving model to Gabis_1549897763.h5\n",
      "704/704 [==============================] - 227s 323ms/step - loss: 1.9814 - acc: 0.4966 - val_loss: 2.4887 - val_acc: 0.4401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21c92a8a898>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = LossAccHistory()\n",
    "model_final.fit_generator(generator=train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   validation_data = validation_generator,\n",
    "                   epochs=25\n",
    "                   ,callbacks = [history, checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
